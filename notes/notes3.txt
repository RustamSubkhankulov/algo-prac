= задача СОРТИРОВКИ: 
последовательность ключей должна быть упорядочена 
по невозрастанию(неубыванию)

= алгоритм УСТОЙЧИВЫЙ, если он сохраняет отн порядок 
эл-тов с одинаковыми ключами - относительно изначального

= сортировки, сравнивающие элементы для их упорядочивания -
сортировки СРАВНЕНИЕМ

less(a,b)
!less(a,b) && !less(b,a) -> eq(a,b)=True

= ИНВЕРСИЯ - пара ключей с нарушенным порядком следования
  в отсортированнм мн-ве количество инверсий равно нулю

= 1. BUBBLE sort 
- simple
- steady
- best  O(n), worst O(n^2)
- in-place

void bubbleSort(int arr[], int n)
{
  int i, j;
  bool swapped;
  for (i = 0; i < n - 1; i++) {
    swapped = false;
    for (j = 0; j < n - i - 1; j++) {
      if (arr[j] > arr[j + 1]) {
        swap(arr[j], arr[j + 1]);
        swapped = true;
      }
    }

    // If no two elements were swapped
    // by inner loop, then break
    if (swapped == false)
      break;
  }
}

= 2. INSERTION sort
- steady
- best O(n), worst O(n^2)
- in-place
- online-algorithm - new elem for O(n)

после i-го прохода в первых i позициях 
элементы отсортированы

void insertionSort(int arr[], int n)
{
  for (int i = 1; i < n; i++) {
    
    int j = i;
    int key = arr[i];

    while (j >= 1 && arr[j-1] > key) {
      arr[j] = arr[j-1];
      j = j - 1;
    }
    arr[j] = key;
  }
}

= 3. SHELL sort
- not steady
- best O(n), worst O(N^(3/2))
- in-place
- низкий коэф амортизации, конкурентно-способен при малых N

void shellsort(int *a, int n) {
  int h;
  
  for (h = 1; h <= n / 9; h = 3*h + 1)
    ;
  
  // iterations with different gaps
  for ( ; h > 0; h /= 3) {
    
    for (int i = h; i < n; i++) {
      
      int j = i;
      int tmp = a[i];
      
      while (j >= h && a[j-h] > tmp) {
        a[j] = a[j-h];
        j -= h;
      }
      
      a[j] = tmp;
    }
  }
}

= 4. SELECTION sort
- steady, if we stop at the first min element
- complexity always O(n^2)
- in-place
- O(n) swap operations - for arrays with large elements
                         that are fast-comparable

void selectionSort(int arr[], int n) 
{ 
  int i, j, min_idx; 

  for (i = 0; i < n - 1; i++) { 

    min_idx = i; 
    for (j = i + 1; j < n; j++) { 
      if (arr[j] < arr[min_idx]) 
          min_idx = j; 
    } 

    if (min_idx != i) 
      swap(arr[min_idx], arr[i]); 
  } 
}

= k-ая порядковая статистика
k-ый по упорядочиванию величины элемент

если операция упор. это less, то min элемент - 
первая порядковая статистика

max elem - N-тая порядковая статистика
МЕДИАНА - средний по величине, но не среднее! "середина"

= 5. ВЫБОРКА SELECTION
            Selection(Sl, k), k <= |Sl|
Selection = pivot, |Sl| < k <= |Sl| + |Spivot| 
            Selection(Sr, k - |Sl| - |Spivot|), k > |Sl| + |Spivot|

complexity O(n), O(n^2) in worst case

= 6. QUICK sort
- steady
- O(nlogn), worst O(n^2) 
  (median of the three random to decrese probability)
- in-place
- memory for frames - O(n)

можно выбрать порог для перехода на обычную сортировку - 
к примеру обменом (пузырьком)

int partition(int arr[],int low,int high)
{
  int pivot=arr[high]; 
  // (in this algo the last element is always picked as pivot)
  int i=(low-1);
   
  for(int j=low;j<=high;j++)
  {
    if(arr[j]<pivot)
    {
      i++;
      swap(arr[i],arr[j]);
    }
  }
  swap(arr[i+1],arr[high]);
  return (i+1);
}
 
void quickSort(int arr[],int low,int high)
{
  if(low<high)
  {
    int pi=partition(arr,low,high);
     
    quickSort(arr,low,pi-1);
    quickSort(arr,pi+1,high);
  }
}

= 7. MERGE sort
двухпутевое слияние отсортированных массивов - O(n)
декомпозиция - O(1)
для маленьких порог - переход на пузырек

- steady
- always O(nlogn)
- not in-place, O(N) for merging
- memory for frames O(N)

void mergeSort(int a[], int low, int high) {
  
  if (high - low < THRESHOLD) {
    plainSort(a, low, high);
  } else {

    int mid = (low + high) / 2;
    
    mergeSort(a, low, mid);
    mergeSort(a, mid+1, high);
    
    merge(a, low, mid, high);
  }
}

= BETTER THAN O(nlogn) is impossible for сортировки сравнением

= 8. Сортировка ПОДСЧЕТОМ
- ключи перечислимы, могут быть индексами в массиве счётчиков
- ограниченное число ключей
- память O(|D(K|)
- O(|D(K)|) + O(n) + O(|D(K)|) = O(|D(K)|) + O(n)

= 9. ПОРАЗРЯДНАЯ сортировка
- ключи деляться на фрагменты, удовл требованиям сортировки подсчетом
- память O(|D(Ki|)
- сложность O(N|D(Ki|)
- быстрее делить не на 10ные разряды, а на биты

= ВНЕШНЯЯ сортировка
сортировка при недостатке внешней памяти

= 9. Внешняя merge sort
делим файлы на чанки, грузим в память, сортируем, записываем

= 10. Сортировка сериями
выделяем постепенно серии увеличивающейся длины
которые попарно сливаются обратно в файл
память нужна для ДВУХ ЭЛЕМЕНТОВ!
- log2(N) проходов, O(nlogn)
- memory O(1)
- улучшение - предварительно сортируем чанки максимальным
  помещающимся в память размером, сортировку слиянием 
  начинаем с k0 итерации

 _____________________________________________
|____________|BEST_|AVER_|WORST|MEMORY|STEADY |
|BUBBLE      |N    |N^2  |N^2  |1     |Y      |
|SHELL       |N^7/6|N^7/6|N^4/3|1     |N      |
|INSERTION   |N    |N^2  |N^2  |1     |Y      |
|SELECTION   |N    |N^2  |N^2  |1     |Y      |
|QUICK       |NlogN|NlogN|N^2  |1     |Y      |
|MERGE       |NlogN|NlogN|NlogN|1     |Y      |
|ПОДСЧЕТОМ   |N    |N    |N    |N     |Y      |
|ПОРАЗРЯДНАЯ |N    |N    |N    |N     |Y      |
 ---------------------------------------------

= TIMSORT
best N, worst NlogN, aver NlogN, steady

Шаг 0. Вычисление minrun.

Число minrun определяется на основе N исходя из следующих принципов:
Оно не должно быть слишком большим, поскольку к подмассиву размера minrun будет в дальнейшем применена сортировка вставками, а она эффективна только на небольших массивах
Оно не должно быть слишком маленьким, поскольку чем меньше подмассив — тем больше итераций слияния подмассивов придётся выполнить на последнем шаге алгоритма.
Хорошо бы, чтобы N \ minrun было степенью числа 2 (или близким к нему). Это требование обусловлено тем, что алгоритм слияния подмассивов наиболее эффективно работает на подмассивах примерно равного размера.

int GetMinrun(int n)
  {
    int r = 0;           /* станет 1 если среди сдвинутых битов будет хотя бы 1 ненулевой */
    while (n >= 64) {
      r |= n & 1;
      n >>= 1;
    }
    return n + r;
  }


Шаг 1. Разбиение на подмассивы и их сортировка.
Итак, на данном этапе у нас есть входной массив, его размер N и вычисленное число minrun. Алгоритм работы этого шага:
Ставим указатель текущего элемента в начало входного массива.
Начиная с текущего элемента, ищем во входном массиве run (упорядоченный подмассив). По определению, в этот run однозначно войдет текущий элемент и следующий за ним, а вот дальше — уже как повезет. Если получившийся подмассив упорядочен по убыванию — переставляем элементы так, чтобы они шли по возрастанию (это простой линейный алгоритм, просто идём с обоих концов к середине, меняя элементы местами).
Если размер текущего run'а меньше чем minrun — берём следующие за найденным run-ом элементы в количестве minrun — size(run). Таким образом, на выходе у нас получается подмассив размером minrun или больше, часть которого (а в идеале — он весь) упорядочена.
Применяем к данному подмассиву сортировку вставками. Так как размер подмассива невелик и часть его уже упорядочена — сортировка работает быстро и эффективно.
Ставим указатель текущего элемента на следующий за подмассивом элемент.
Если конец входного массива не достигнут — переход к пункту 2, иначе — конец данного шага.


Шаг 2. Слияние.
Создаем пустой стек пар <индекс начала подмассива>-<размер подмассива>. Берём первый упорядоченный подмассив.
Добавляем в стек пару данных <индекс начала>-<размер> для текущего подмассива.
Определяем, нужно ли выполнять процедуру слияния текущего подмассива с предыдущими. Для этого проверяется выполнение 2 правил (пусть X, Y и Z — размеры трёх верхних в стеке подмассивов):
X > Y + Z
Y > Z
Если одно из правил нарушается — массив Y сливается с меньшим из массивов X и Z. Повторяется до выполнения обоих правил или полного упорядочивания данных.
Если еще остались не рассмотренные подмассивы — берём следующий и переходим к пункту 2. Иначе — конец.

2.1 Процедура слияния подмассивов
Как Вы помните, на втором шаге алгоритма мы занимаемся слиянием двух подмассивов в один упорядоченный. Мы всегда соединяем 2 последовательных подмассива. Для их слияния используется дополнительная память.
Создаём временный массив в размере меньшего из соединяемых подмассивов.
Копируем меньший из подмассивов во временный массив
Ставим указатели текущей позиции на первые элементы большего и временного массива.
На каждом следующем шаге рассматриваем значение текущих элементов в большем и временном массивах, берём меньший из них и копируем его в новый отсортированный массив. Перемещаем указатель текущего элемента в массиве, из которого был взят элемент.
Повторяем 4, пока один из массивов не закончится.
Добавляем все элементы оставшегося массива в конец нового массива.

2.2 Модификация процедуры слияния подмассивов

Всё, вроде бы, хорошо в показанном выше алгоритме слияния. Кроме одного. Представьте себе процедуру слияния двух вот таких массивов:
A = {1, 2, 3,..., 9999, 10000}
B = { 20000, 20001, ...., 29999, 30000}
Вышеуказанная процедура для них, конечно, сработает, но каждый раз на её четвёртом пункте нужно будет выполнить одно сравнение и одно копирование. И того 10000 сравнений и 10000 копирований. Алгоритм Timsort предлагает в этом месте модификацию, которую он называет «галоп». Суть в следующем:
Начинаем процедуру слияния, как было показано выше.
На каждой операции копирования элемента из временного или большего подмассива в результирующий запоминаем, из какого именно подмассива был элемент.
Если уже некоторое количество элементов (в данной реализации алгоритма это число жестко равно 7) было взято из одного и того же массива — предполагаем, что и дальше нам придётся брать данные из него. Чтобы подтвердить эту идею, мы переходим в режим «галопа», т.е. бежим по массиву-претенденту на поставку следующей большой порции данных бинарным поиском (мы помним, что массив упорядочен и мы имеем полное право на бинарный поиск) текущего элемента из второго соединяемого массива. Бинарный поиск эффективнее линейного, а потому операций поиска будет намного меньше.
Найдя, наконец, момент, когда данные из текущего массива-поставщика нам больше не подходят (или дойдя до конца массива), мы можем, наконец, скопировать их все разом (что может быть эффективнее копирования одиночных элементов).

Возможно, объяснение слегка туманно, попробуем на примере.
A = {1, 2, 3,..., 9999, 10000}
B = { 20000, 20001, ...., 29999, 30000}
Первые 7 итераций мы сравниваем числа 1, 2, 3, 4, 5, 6 и 7 из массива A с числом 20000 и, убедившись, что 20000 больше — копируем элементы массива A в результирующий.
Начиная со следующей итерации переходим в режим «галопа»: сравниваем с числом 20000 последовательно элементы 8, 10, 14, 22, 38, n+2^i, ..., 10000 массива A. Как видно, таких сравнение будет намного меньше 10000.
Мы дошли до конца массива A и знаем, что он весь меньше B (мы могли также остановиться где-то посередине). Копируем нужные данные из массива A в результирующий, идём дальше.

Вот и весь алгоритм.